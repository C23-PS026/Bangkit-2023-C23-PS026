# -*- coding: utf-8 -*-
"""Capstone ML Model_CNN ReLu

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1umZbCZoF_V5xh-X-VXDa9033TgHDAy7v

# Load Data
"""

import tensorflow as tf
import os

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu, True)

import cv2
import imghdr

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

"""# **Beef & Chicken Fresh & Not Fresh**

---


"""

from PIL import Image
#Load data Sapi vs Ayam
data_dir = '/content/drive/MyDrive/Capstone Project - Yaudaah, Boleeeh, Tenaang/Dataset/dataset_custom_nonkaggle'  # Ganti dengan path gambar Anda di Google Drive

os.listdir(data_dir)

image_exts = ['jpeg','jpg','bmp','png']

for image_class in os.listdir(data_dir):
  for image in os.listdir(os.path.join(data_dir, image_class)):
      image_path = os.path.join(data_dir, image_class, image)
      try:
        img = cv2.imread(image_path)
        tip = imghdr.what(image_path)
        if tip not in image_exts:
          print('Image not in ext list {}'.format(image_path))
          os.remove(image_path)
      except Exception as e:
        print('Issue with image {}'.format(image_path))

import numpy as np
from matplotlib import pyplot as plt

data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Capstone Project - Yaudaah, Boleeeh, Tenaang/Dataset/dataset_custom_nonkaggle')

data_iterator = data.as_numpy_iterator()

batch = data_iterator.next()

# 0 = Beef Fresh
# 1 = Beef Not Fresh
# 2 = Chicken Fresh
# 3 = Chicken Not Fresh
batch[1]

fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])

"""# Scale Data"""

data = data.map(lambda x, y: (x/255, y))

scaled_iterator = data.as_numpy_iterator()

batch = scaled_iterator.next()

fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch[1][idx])

"""# Split Data"""

train_size = int(len(data)*0.6)
val_size = int(len(data)*0.3)
test_size = int(len(data)*0.1)

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

"""DATA AUGMENTATION

"""

from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers

height = 128
width = 128

img_aug = Sequential(
    [
        layers.RandomRotation(factor=0.2),
        layers.RandomTranslation(height_factor=0.15, width_factor=0.15),
        layers.RandomFlip(),
        layers.RandomContrast(factor=0.15),
        layers.RandomZoom(height_factor=0.2, width_factor=0.2),
        layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=0)),
        layers.Lambda(lambda x: image.random_shear(x[0], shear=0.2)),
        layers.Lambda(lambda x: tf.keras.backend.squeeze(x, axis=0)),
        layers.RandomBrightness(factor=0.2),
        layers.RandomCrop(height, width),
        # layers.GlobalAveragePooling2D(),
        # tf.keras.layers.Dropout(.2),
        # tf.keras.layers.Dense(4, activation="softmax")
    ],
    name="img_aug",
)

"""# Save Model"""

from keras.models import load_model

def save_model(model, nama_file):
  files = nama_file+'.h5'
  model.save(files)

"""# Data Modelling

## CNN

#### ReLu
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, MaxPool2D

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation
from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import EarlyStopping

# Define the early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3)

# Creating a Sequential model
model_CNN_ReLU = Sequential()
model_CNN_ReLU.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3), kernel_regularizer=regularizers.l2(0.001)))
model_CNN_ReLU.add(MaxPooling2D())

model_CNN_ReLU.add(Conv2D(32, (3,3), 1, activation='relu', kernel_regularizer=regularizers.l2(0.001)))
model_CNN_ReLU.add(MaxPooling2D())

model_CNN_ReLU.add(Conv2D(16, (3,3), 1, activation='relu', kernel_regularizer=regularizers.l2(0.001)))
model_CNN_ReLU.add(MaxPooling2D())

model_CNN_ReLU.add(Flatten())

model_CNN_ReLU.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))
model_CNN_ReLU.add(Dense(4, activation='softmax'))

model_CNN_ReLU.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

hist_CNN_ReLU = model_CNN_ReLU.fit(train, epochs=200, validation_data=val, verbose=2, batch_size=16)

"""# Evaluate

##Plot Performance

### CNN (ReLU)
"""

fig = plt.figure()
plt.plot(hist_CNN_ReLU.history['loss'], color='teal', label='loss')
plt.plot(hist_CNN_ReLU.history['val_loss'], color='orange', label='val_loss')
fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()

fig = plt.figure()
plt.plot(hist_CNN_ReLU.history['accuracy'], color='teal', label='accuracy')
plt.plot(hist_CNN_ReLU.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()

"""## Precision, Recall, Accuracy"""

from tensorflow.keras.metrics import Precision, Recall, Accuracy

pre = Precision()
re = Recall()
acc = Accuracy()

"""

### CNN (ReLU)"""

for batch in test.as_numpy_iterator(): 
    X, y = batch
    yhat = model_CNN_ReLU.predict(X)
    y_classes = yhat.argmax(axis=-1)
    pre.update_state(y, y_classes)
    re.update_state(y, y_classes)
    acc.update_state(y, y_classes)

print('Precision:',pre.result().numpy(),'Recall:', re.result().numpy(),'Accuracy:',acc.result().numpy())

"""#Test"""

import cv2

img = cv2.imread('/content/daguing segar.jpg')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()

resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()

"""## CNN ReLU"""

yhat = model_CNN_ReLU.predict(np.expand_dims(resize/255, 0))

yhat_max_idx = np.argmax(yhat)

def predict_meat(y):
  if y == 0: 
    print(f'Predicted class is Fresh Beef')
  elif y == 1:
    print(f'Predicted class is Not Fresh Beef')
  elif y == 2:
    print(f'Predicted class is Fresh Chicken')
  elif y == 3:
    print(f'Predicted class is Not Fresh Chicken')
  print('with probability of ', np.round(yhat[0][yhat_max_idx]*100, 2), '%', sep = "")
predict_meat(yhat_max_idx)

"""# Model Saving

## CNN ReLU
"""

save_model(model_CNN_ReLU, 'CNN ReLU') #contoh save model

model_CNN_ReLU = load_model('CNN ReLU.h5') #contoh load model

import tensorflow as tf

# Load the Keras model
model = tf.keras.models.load_model('CNN ReLU.h5')

# Convert the model to TFLite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TFLite model to a file
with open('model.tflite', 'wb') as file:
    file.write(tflite_model)